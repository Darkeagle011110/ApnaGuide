# -*- coding: utf-8 -*-
"""Disaster.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GwTEpmJpxGrgkU8x1Xe0QtNygj09bdxr
"""

! pip install pandas numpy scikit-learn

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score

# Load the datasets
train_data = pd.read_csv('/train.csv')
test_data = pd.read_csv('/test.csv')

# Display the first few rows of the training data
print(train_data.head())

# Handle missing values
train_data['keyword'].fillna('', inplace=True)
train_data['place'].fillna('', inplace=True)
test_data['keyword'].fillna('', inplace=True)
test_data['place'].fillna('', inplace=True)

# Encode categorical features
label_encoders = {}
for feature in ['keyword', 'place']:
    label_encoders[feature] = LabelEncoder()
    # Fit on the combination of train and test data to capture all possible categories
    all_data = pd.concat([train_data[feature], test_data[feature]])
    label_encoders[feature].fit(all_data)
    train_data[feature] = label_encoders[feature].transform(train_data[feature])
    test_data[feature] = label_encoders[feature].transform(test_data[feature])

# Vectorize the tweet text data
vectorizer = TfidfVectorizer(max_features=10000)
X_train_tweets = vectorizer.fit_transform(train_data['tweet'])
X_test_tweets = vectorizer.transform(test_data['tweet'])

# Combine the encoded categorical features with the vectorized text data
X_train = np.hstack((train_data[['keyword', 'place']].values, X_train_tweets.toarray()))
X_test = np.hstack((test_data[['keyword', 'place']].values, X_test_tweets.toarray()))

# Extract the target variable
y_train = train_data['disaster']

# Split the training data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# Train a Random Forest classifier
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Make predictions on the validation set
y_val_pred = model.predict(X_val)

# Evaluate the model on the validation set
val_accuracy = accuracy_score(y_val, y_val_pred)
val_report = classification_report(y_val, y_val_pred)

print(f"Validation Accuracy: {val_accuracy:.2f}")
print("Validation Classification Report:")
print(val_report)

# Make predictions on the test set
y_test_pred = model.predict(X_test)

# Assume the test set has the true labels for evaluation (if available)
# If you have the true labels for the test set, you can evaluate the model as follows:
# y_test_true = test_data['disaster']  # Add the true labels column to your test data
# test_accuracy = accuracy_score(y_test_true, y_test_pred)
# test_report = classification_report(y_test_true, y_test_pred)

# Print the test accuracy and classification report if you have the true labels
# print(f"Test Accuracy: {test_accuracy:.2f}")
# print("Test Classification Report:")
# print(test_report)

# If true labels for the test set are not available, you can only print the predictions
print("Test Predictions:")
print(y_test_pred)